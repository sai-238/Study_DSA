ARRAY
    => We can access a given item based on the index extremely fast in array which is known as random access.  
    => the time complexity foer the above item access is O(1).
        
        search              = O(1)
        insert at the start = O(N)
        insert at the end   = O(1)
        waste space         = 0
        remove an item with the index = O(N)
        remove an item at arbitary position = O(N)


LIST 
    => the first conclusion that everything is an object in Python : list stores the references and not the acutal value. 
    => In a list of elements a number's example { 21,23,4,5,6 } it does not sotre 23 it store's the reference which is pointing to 23.
    => each refrence is 8 bytes in size.  
    

NUMPY 
    * Is a python library, where array's are stored in a continuous block of memory - item's are right next to each other. 
    * The references are located right next to each other but the items that the refrences are pointing is located in different regions of memory.   


LINKED_LIST
    => It's main moto to store elements in efficient way 
    => In array we have a huge disadvantage : we have to shift a lot of items to store a item in a specific spot 
        * This problem is solved with the help of LINKED_LIST
    => We have to start with the head node inorder to go to the desired node.
        * Ever node store's the data itself and reference of the next node. 
        * The last node's reference is always null.
        * That's why LINKED_LIST'S need more memmory than array's   
    => random access is not possible in linked LINKED_LIST
        
        search              = O(N)
        insert at the start = O(1)  
        insert at the end   = O(N)
        waste space         = 0
        remove an item      = O(N)
        remove the current item = O(1)


DOUBLY_LINKED_LIST
    => It's main moto to store and remove elements in efficient way same as linked list 
    => We have to start with the head node inorder to go to the desired node.
        * Ever node store's the data itself and reference of the next node and refrence of the previous node. 
        * The last node's next reference is always null.
        * That's why DOUBLY_LINKED_LIST need more memmory than LINKED_LIST'S
    => random access is not possible as same as LINKED_LIST
    => We can access the DOUBLY_LINKED_LIST in both direction ( From Backward aswell ) 

        search              = O(N)
        insert at the start = O(1)  
        insert at the end   = O(1)
        waste space         = 0
        remove an item      = O(N)
        remove the current item = O(1)


STACK
    --> It is a abstract data type 
    --> It has a so called LIFO ( last in first out ) structure  - last item we inserted is the first item we take out 
    --> Basic operation's are pop(), peek() and push()


MEMORY MANAGEMENT 
    STACK MEMORY
        ~~> Stack Memory is a special region in the RAM  ( Random access memmory )
        ~~> This is a special data type ( Stack ) that stores local variables and method calls
        ~~> It is small in size but fast to access 
        ~~> No Fragmentation ( Fragmentation :Memory fragmentation is when the sum of the available space in a memory heap is large enough to satisfy memory allocation request but
                             the size of any individual fragment (or contiguous fragments) is too small to satisfy that memory allocation request )

    HEAP MEMORY
        ~~> Heap memory is a special region in the RAM, where dynamic memory allocation takes place 
        ~~> The size of the heap memory is way larger than the size of the stack memory
        ~~> It is large in size but slow to access 


QUEUE
    __> It is a abstract data type - and it can be implemented either with with array or with linked list.
    __> It has so called FIFO structure - first item we insert is the first we take out.
    __> Basic operation's are enqueue() , dequeue() and peek().
    __> Has several application like operating system and thread mangement and queues are important in CPU scheduling.


TREE
    ++> Tree is a G(Vertices , Edge's) undirected in which any two vertices are connected by exactly one patch or equivalently a connected acyclic undirected graph.
    ++> Tree like structure's are used in operating system's especially like window's all the file's are stored in tree like structure.
    ++> To access all the node's we have access the root node exclusively   
    ++> There are so called leaf node's where there are no children node's connected to it 
    ++> There are parent node where you can heve atleast one child node to as many you want or as many given
    ++> The running time of the binary search trees depends on the h height of the binary search tree.
    ++> oprating systems relies heavily on this data structure.  
        
    BINARY SEARCH TREE'S 
        $$> If we store in a sorted order - Then we can achieve O(logN) running time !! It's aim to store the item's efficiently
        $$> Every node in the tree can have at most 2 children ( left child and right child )
        $$> Left child is smaller than parent node 
        $$> Right child is greater than parent node 
        $$> Every decision can get rid of half of the data and this is how we achieve O(logN) running time
        $$> We have to consider a sorted order in the tree,    
            $$$> The smallest item or node in the right subtree is called successor
            $$$> The largest item or node in the left subtree is called predecessor
        $$$> No random access in tree's ,the tree may be imbalanced and also has no O(1) operation's as well 
        
        search              = O(logN)
        insertion           = O(logN)
        remove an item      = O(logN)

        HEIGHT OF THE TREE : is the number of edges on the longest downward path between the root and a leaf node ,h = logN we have to maintain this h = logN to implement the opreation's at O(logN).
                height of the leaf node = 0
                height of the null node = -1
            height = max( left child's height + right child's height ) + 1 
            
    AVL TREE'S 
        %%> This data structure is very similar to binary search trees, but it is so called balanced binary search tree 
        %%> It has a guaranteed O(logN) running time 
        %%> AVL tree's are faster than the red-black tree It provides extremely fast-look-ups( Search operations).
        %%> This algorithm is going to check whether the tree is balance or not in every iteration's and if the tree is imbalanced then we have to make rotations.
        %%> | h^left - h^right | > 1 all subtrees height parameter can not differ more than 1 
        %%> Usually the difference in the height parameters is called balance factor
        
        ROTATION'S 
            %%> There are two case's
                    :: Left-heavy case = When the left subtree contains more node's and when the balance factors are positive ,then we have to make right rotation.
                    :: Right-heavy case = When the right subtree contains more node's and when the balance factors are negative ,then we have to make left rotation.
            %%> Rotation's are extremely fast - we just have to update the refrences in O(1) constant running time 
            %%> Rotation's does not change the properties of the tree.
            %%> In order traversal remains the same as well as the parent-child replationship in the tree.
            %%> There may be other issuse because of rotations
                    :: we have to check upto the root node whether to make further roatations or not - it takes O(logN) running time.
         
            %%> 
                
        search              = O(logN)
        insertion           = O(logN)
        remove an item      = O(logN)

    RED-BLACK TREE's
        @@> Red black tree are faster to constuct because it is not as balanced as AVL Trees (But it is not as fast as AVL Trees)
        @@> It has a guaranteed =O(logN) running time.
        @@> We have to track the red-black properties for all the node in the binary tree, have to make rotations if necessary to rebalance search trees.
        @@> we always insert new nodes with color red,ROOT NODE IS ALWAYS BLACK ( so we have to recolor )
        @@>For insert intensive applications it is best option, inserting new item is extreamly fast.

        PROPERTIE'S
            1: Each node is either black or red 
            2: The root node is always black
            3: All lead nodes (NULL pointer's) are black
            4: Every red node must have two black child nodes and no other children- it must have a black parent.
            5: Every path from a given node to any of its descendant NULL nodes contains the same number of black nodes. 

        search              = O(logN)
        insertion           = O(logN)
        remove an item      = O(logN)


HEAP
    --> Heaps are basically binary trees.
    --> Heaps are complete binary tree so it cannot be imbalanced.
    --> We will use one dimensional array to represent the item's in the heap.
    --> We insert items from left to right across each row.
    --> formula to find the i^th child, If lef child = 2*i + 1 , If right child = 2*i + 1.
    --> formula to find the parent of i^th child = i - 1 // 2 
    
        searching               = O(LogN)
        Find min / max          = O(1) 
        insertion               = O(logN)
        removing root node      = O(logN)
        remove an arbitary item = O(N) + O(logN) = O(N)

    PRIORITY QUEUES 
        ->> It is a abstract data type such as queue.
        ->> Every item has an additional property - the so -called priority value.
        ->> In priority queue an element with high priority is serverd before an element with lower priority.
        ->> priority queues are usually implemented with heap data structure but it can be implemented with self balancing trees as well.

    HEAPSORT
        --< It is a comparison-based sorting algorithm.
        --< We can constuct a sorting algorithm based on the heap data structure.     
        --< We can achive at O(NlogN) running time for sorting.
        --< It is bit slower in practice on most machines than as well-implemneted quicksort.
        --< It is a in-place algorithm ( DOES NOT NEED ADDITIONAL MEMORY ). 

            insertion = O(NlogN)
      
    Binary Heap 
        >> Max Heap 
            ->> In a max heap the keys of parent node are always greater than or equal to those of the children. The highest key(max value) is in the root node.           
            ->> We can get the max value in O(1) running. 
        >> Min Heap
            ->> In min heap the keys of parent node are less than or equal to those of the children. The highest key(min value) is in the root node.
            ->> We can get the min value in O(1) running. 
       
            Find min            = O(1)
            delete min          = O(logN)
            insertion           = O(logN)
            decrease key (swap) = O(logN)
            merge               =  -

    BINOMIAL HEAP
        ~~< Similar to binary heap but also supports quick merging of two heaps. 
        ~~< A binomial heap is implemented as a collection trees.
        ~~< O(logN) insertion time complexity can be reduced to O(1) constant time complexity.   

            Find min            = O(1)
            delete min          = O(logN)
            insertion           = O(1)
            decrease key (swap) = O(logN)
            merge               = O(logN)

    FIBONACCI HEAP 
        ##> Fibonacci heaps are faster than the classic binary heap and also binomial heap.
        ##> But it is very hard to implement efficiently so usually does not worth the effort  
        ##> Unlike binary heaps it can have several children - the number of children are usually kept low.
        ##> We can achieve O(1) running time for insertion operation instead of O(logN) running time.

            Find min            = O(1)
            delete min          = O(logN)
            insertion           = O(1)
            decrease key (swap) = O(1)
            merge               = O(1)    

ASSOCIATIVE ARRAYS
    (-) Associative arrays ( maps and dictionaries ) are abstract data types.
    (-) Composed of a collection of key- valu pairs where eacch key appears at mosst once in the collection.
    (-) Most of the timmes we implement associative arrays with hastables but binary search trees can be used as well 
    (-) The aim is to reach O(1) time complexity for most of the operations.
     
    HASHTABLES
        [-] The motivation is that we want to store (key, value) pairs  efficiently - so that the insert and remove operations takes O(1) running time.
        [-] Keys must be unique to avoid using the same indexes.
        [-] h(x) hash-function tranforms the keys into an index in range [0,m-1].
        [-] It should handle any types - strings, floats, integer or even custom object as well.
        [-] If we have integer keys we just have to use the modulo ( % ) operator to transform the number into range [0, m-1].
        [-] We can use the ASCCII valuse of the letters when dealing with strings.

            search              = O(1)
            insertion           = O(1)
            deletion            = O(1)
            
            COLLISIONS
                {-} Collisions occur when the h(x) hash-function maps two keys to the same array slot (bucket).
                {-} If thee hash-function is perfect then there are no collision.
                {-} There are several approaches to deal with collisions: CHAINING , OPEN ADRESSING
                {-} The size of the array should be a prime number in order to make sure the items are distributed uniformly - and there are as few collisions as possible.
                
                CHAINING 
                    <-> We store items in the same array (bucket) with same indexes in a llinked list data structure.
                    <-> In worst case senario we may end up in LINKED_LIST with O(N) running time for most of the operations.

                OPEN ADDRESSING  
                    <-> If there is a collision we generate a new index for the item (try to find another bucket).
                        
                        LINEAR PROBING
                            "-" If collision happened at array index k then we try k+1, k+2, k+3,... until we find an empty bucket.
                            "-" But it has the better cache performance than other approaches.

                        QUADRATIC PROBING 
                            "-" If collision happpend at array index k then we try successive values of an 
                                arbitary quadratic polynomial (array slots 1,4,9,16,.., steps away from the collision).
                            "-" there will be no clusters (unlike linear probing ).
                            "-" But no cache advantages ( items are far away in memory ).  

                        REHASING
                            "-" IF collision happened at array index k then we use the h(x) hash-function again to generate a new index.

            LOAD FACTOR 
                {-} The p(x) probability of collision is not constant.
                {-} The more items are there in the hastable the higher the p(x) probability of collision.
                {-} This is why we have to define a new parameter of the hashtable - the so-called load factor.
                {-} Load Factor = the number of actual items (n) / (m) the size of the array.
                {-} Based on load factor we can resize the hashtable.
                {-} Python ( when load factor > 0.66 ) and java ( When load factor > 0.75 ) resize the hashtable automatically to avoid too many collisions.

                SMALL LOAD FACTOR
                    <-> The hastable is nearly empty which means low p(x) probability of collisions.
                    <-> But of course a lot of memory is wasted.

                HIGH LOAD FACTOR
                    <-> The hastable is nearly full which means high p(x) probability of collisions.
                    <-> No memory is wasted but the running time may be reduced to O(N) linear running time.

